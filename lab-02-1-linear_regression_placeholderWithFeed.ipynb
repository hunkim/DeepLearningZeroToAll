{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lab 2 Linear Regression\n",
    "\n",
    "\n",
    "## TensorFlow Mechanics \n",
    "\n",
    "### - Build graph using TensorFlow operations\n",
    "### - feed data and run graph (operation)\n",
    "sess.run (op, feed_dict={x: x_data}) \n",
    "### - update variables in the graph (and return values) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Use placeholder to set x and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# x and y data\n",
    "# x_train = [1,2,3]\n",
    "# y_train = [1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to find values for W and b to compute $$y = W * x+ b $$\n",
    "We know that $W$ should be $1$ and $b$ should be $0$\n",
    "But let's use TensorFlow to figure it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## placeholders for a tensor that will be always fed using feed_dict\n",
    "X = tf.placeholder(tf.float32,shape=[None])\n",
    "Y = tf.placeholder(tf.float32,shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step,sess.run(cost),sess.run(W),sess.run(b)\n",
      "0 0.229185 [ 0.43071482] [ 1.24572289]\n",
      "20 0.205754 [ 0.47276995] [ 1.19390953]\n",
      "40 0.186847 [ 0.49900481] [ 1.13844085]\n",
      "60 0.169697 [ 0.52268845] [ 1.08499968]\n",
      "80 0.154122 [ 0.54513347] [ 1.03401446]\n",
      "100 0.139976 [ 0.56651187] [ 0.98542005]\n",
      "120 0.127128 [ 0.58688432] [ 0.93910903]\n",
      "140 0.11546 [ 0.60629922] [ 0.89497441]\n",
      "160 0.104863 [ 0.6248017] [ 0.85291392]\n",
      "180 0.0952379 [ 0.64243466] [ 0.81283015]\n",
      "200 0.0864966 [ 0.65923887] [ 0.77463013]\n",
      "220 0.0785576 [ 0.67525333] [ 0.7382254]\n",
      "240 0.0713472 [ 0.69051528] [ 0.70353144]\n",
      "260 0.0647987 [ 0.70505989] [ 0.67046815]\n",
      "280 0.0588512 [ 0.71892101] [ 0.63895869]\n",
      "300 0.0534496 [ 0.73213071] [ 0.60892999]\n",
      "320 0.0485438 [ 0.74471956] [ 0.58031249]\n",
      "340 0.0440883 [ 0.75671685] [ 0.55303991]\n",
      "360 0.0400416 [ 0.76815021] [ 0.52704906]\n",
      "380 0.0363665 [ 0.7790463] [ 0.50227982]\n",
      "400 0.0330286 [ 0.78943032] [ 0.47867441]\n",
      "420 0.0299971 [ 0.79932636] [ 0.45617846]\n",
      "440 0.0272438 [ 0.80875719] [ 0.43473977]\n",
      "460 0.0247433 [ 0.81774497] [ 0.41430861]\n",
      "480 0.0224723 [ 0.82631028] [ 0.39483765]\n",
      "500 0.0204097 [ 0.83447307] [ 0.37628168]\n",
      "520 0.0185364 [ 0.84225225] [ 0.35859779]\n",
      "540 0.016835 [ 0.84966576] [ 0.34174502]\n",
      "560 0.0152899 [ 0.85673088] [ 0.32568422]\n",
      "580 0.0138865 [ 0.863464] [ 0.31037831]\n",
      "600 0.0126119 [ 0.86988074] [ 0.29579166]\n",
      "620 0.0114544 [ 0.87599587] [ 0.28189051]\n",
      "640 0.010403 [ 0.8818236] [ 0.26864269]\n",
      "660 0.0094482 [ 0.88737738] [ 0.25601751]\n",
      "680 0.00858101 [ 0.89267033] [ 0.24398564]\n",
      "700 0.00779341 [ 0.89771432] [ 0.23251919]\n",
      "720 0.00707811 [ 0.90252143] [ 0.22159168]\n",
      "740 0.00642845 [ 0.90710258] [ 0.21117769]\n",
      "760 0.00583842 [ 0.91146839] [ 0.20125313]\n",
      "780 0.00530254 [ 0.91562903] [ 0.19179495]\n",
      "800 0.00481586 [ 0.91959417] [ 0.18278134]\n",
      "820 0.00437383 [ 0.92337292] [ 0.17419128]\n",
      "840 0.00397239 [ 0.92697412] [ 0.16600497]\n",
      "860 0.00360779 [ 0.93040609] [ 0.15820338]\n",
      "880 0.00327666 [ 0.93367672] [ 0.15076838]\n",
      "900 0.00297591 [ 0.93679368] [ 0.14368281]\n",
      "920 0.00270277 [ 0.9397642] [ 0.13693021]\n",
      "940 0.00245469 [ 0.94259506] [ 0.13049498]\n",
      "960 0.00222939 [ 0.94529289] [ 0.12436217]\n",
      "980 0.00202477 [ 0.94786388] [ 0.11851761]\n",
      "1000 0.00183893 [ 0.95031416] [ 0.11294767]\n",
      "1020 0.00167014 [ 0.95264918] [ 0.10763953]\n",
      "1040 0.00151685 [ 0.95487446] [ 0.10258089]\n",
      "1060 0.00137763 [ 0.95699525] [ 0.09775995]\n",
      "1080 0.00125119 [ 0.95901626] [ 0.09316561]\n",
      "1100 0.00113634 [ 0.96094239] [ 0.08878718]\n",
      "1120 0.00103205 [ 0.96277797] [ 0.0846145]\n",
      "1140 0.000937322 [ 0.96452725] [ 0.08063791]\n",
      "1160 0.000851288 [ 0.96619439] [ 0.07684822]\n",
      "1180 0.000773155 [ 0.96778309] [ 0.07323661]\n",
      "1200 0.000702193 [ 0.96929699] [ 0.0697948]\n",
      "1220 0.000637743 [ 0.97074014] [ 0.0665147]\n",
      "1240 0.000579209 [ 0.97211516] [ 0.06338873]\n",
      "1260 0.000526047 [ 0.97342569] [ 0.06040968]\n",
      "1280 0.000477762 [ 0.97467452] [ 0.05757067]\n",
      "1300 0.000433915 [ 0.97586477] [ 0.05486508]\n",
      "1320 0.000394086 [ 0.97699898] [ 0.05228663]\n",
      "1340 0.000357916 [ 0.97807992] [ 0.04982936]\n",
      "1360 0.000325065 [ 0.97911018] [ 0.0474876]\n",
      "1380 0.000295227 [ 0.98009199] [ 0.04525584]\n",
      "1400 0.000268132 [ 0.98102754] [ 0.04312894]\n",
      "1420 0.000243521 [ 0.98191917] [ 0.04110201]\n",
      "1440 0.00022117 [ 0.98276889] [ 0.03917036]\n",
      "1460 0.000200869 [ 0.98357868] [ 0.03732951]\n",
      "1480 0.000182433 [ 0.98435044] [ 0.03557515]\n",
      "1500 0.000165689 [ 0.98508596] [ 0.03390321]\n",
      "1520 0.000150482 [ 0.9857868] [ 0.03230989]\n",
      "1540 0.000136668 [ 0.98645484] [ 0.03079144]\n",
      "1560 0.000124125 [ 0.98709136] [ 0.02934435]\n",
      "1580 0.000112732 [ 0.98769802] [ 0.02796528]\n",
      "1600 0.000102384 [ 0.98827618] [ 0.02665101]\n",
      "1620 9.29877e-05 [ 0.98882711] [ 0.02539854]\n",
      "1640 8.44532e-05 [ 0.98935223] [ 0.02420491]\n",
      "1660 7.67033e-05 [ 0.98985249] [ 0.02306746]\n",
      "1680 6.96626e-05 [ 0.99032956] [ 0.02198339]\n",
      "1700 6.32691e-05 [ 0.99078393] [ 0.02095023]\n",
      "1720 5.74607e-05 [ 0.99121714] [ 0.01996563]\n",
      "1740 5.21863e-05 [ 0.99162984] [ 0.01902729]\n",
      "1760 4.73968e-05 [ 0.99202323] [ 0.01813306]\n",
      "1780 4.30465e-05 [ 0.99239814] [ 0.01728087]\n",
      "1800 3.90962e-05 [ 0.99275541] [ 0.01646871]\n",
      "1820 3.55073e-05 [ 0.99309582] [ 0.01569475]\n",
      "1840 3.22487e-05 [ 0.9934203] [ 0.01495717]\n",
      "1860 2.92882e-05 [ 0.99372953] [ 0.01425426]\n",
      "1880 2.66005e-05 [ 0.99402422] [ 0.01358436]\n",
      "1900 2.41589e-05 [ 0.99430501] [ 0.01294596]\n",
      "1920 2.19418e-05 [ 0.99457264] [ 0.01233756]\n",
      "1940 1.9928e-05 [ 0.99482775] [ 0.01175777]\n",
      "1960 1.80985e-05 [ 0.99507087] [ 0.01120516]\n",
      "1980 1.64372e-05 [ 0.9953025] [ 0.01067854]\n",
      "2000 1.49292e-05 [ 0.99552321] [ 0.0101767]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# W weight and b bias\n",
    "W = tf.Variable(tf.random_normal([1]),name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "# our hypothsis\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# GradientDescent to Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# launch the graph in a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# inintializes global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"step,sess.run(cost),sess.run(W),sess.run(b)\")\n",
    "# fit the line\n",
    "for step in range(2001):\n",
    "    cost_val,W_val,b_val,_ = sess.run([cost,W,b,train],feed_dict = {X: [1, 2, 3], Y: [1, 2, 3]})\n",
    "    if step % 20 == 0:\n",
    "        print(step,cost_val,W_val,b_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can easily find that \n",
    "### Learns best fit W:[ 1.],  b:[ 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.98779297]\n",
      "[ 2.49898481]\n",
      "[ 1.50346148  3.49450779]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the line with new training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.21721 [ 1.06189752] [ 0.03224177]\n",
      "20 0.1625 [ 1.25983024] [ 0.15811706]\n",
      "40 0.141894 [ 1.24372602] [ 0.22005443]\n",
      "60 0.123917 [ 1.22776818] [ 0.27768394]\n",
      "80 0.108218 [ 1.21285164] [ 0.33153811]\n",
      "100 0.0945076 [ 1.19891179] [ 0.38186523]\n",
      "120 0.0825341 [ 1.18588483] [ 0.42889649]\n",
      "140 0.0720777 [ 1.17371118] [ 0.47284761]\n",
      "160 0.062946 [ 1.16233456] [ 0.51392037]\n",
      "180 0.0549712 [ 1.15170312] [ 0.55230319]\n",
      "200 0.0480067 [ 1.1417681] [ 0.58817226]\n",
      "220 0.0419246 [ 1.13248348] [ 0.62169224]\n",
      "240 0.0366131 [ 1.12380719] [ 0.65301692]\n",
      "260 0.0319745 [ 1.11569893] [ 0.68229014]\n",
      "280 0.0279236 [ 1.10812175] [ 0.70964628]\n",
      "300 0.0243859 [ 1.10104072] [ 0.73521072]\n",
      "320 0.0212964 [ 1.09442353] [ 0.75910109]\n",
      "340 0.0185983 [ 1.08823967] [ 0.78142679]\n",
      "360 0.0162421 [ 1.08246076] [ 0.80229026]\n",
      "380 0.0141843 [ 1.07706034] [ 0.8217876]\n",
      "400 0.0123872 [ 1.07201362] [ 0.84000796]\n",
      "420 0.0108179 [ 1.06729734] [ 0.8570351]\n",
      "440 0.00944731 [ 1.06288993] [ 0.87294716]\n",
      "460 0.00825042 [ 1.05877125] [ 0.88781697]\n",
      "480 0.00720514 [ 1.05492234] [ 0.90171307]\n",
      "500 0.00629231 [ 1.05132532] [ 0.91469896]\n",
      "520 0.00549512 [ 1.04796398] [ 0.92683446]\n",
      "540 0.00479893 [ 1.04482281] [ 0.9381752]\n",
      "560 0.00419093 [ 1.0418874] [ 0.94877332]\n",
      "580 0.00365997 [ 1.03914404] [ 0.95867723]\n",
      "600 0.00319629 [ 1.03658056] [ 0.96793246]\n",
      "620 0.00279135 [ 1.03418493] [ 0.97658157]\n",
      "640 0.0024377 [ 1.03194618] [ 0.98466432]\n",
      "660 0.00212887 [ 1.02985394] [ 0.9922176]\n",
      "680 0.00185915 [ 1.02789879] [ 0.9992764]\n",
      "700 0.00162362 [ 1.02607167] [ 1.00587296]\n",
      "720 0.0014179 [ 1.02436411] [ 1.01203763]\n",
      "740 0.00123827 [ 1.0227685] [ 1.0177983]\n",
      "760 0.00108139 [ 1.02127743] [ 1.02318168]\n",
      "780 0.000944385 [ 1.01988387] [ 1.02821267]\n",
      "800 0.00082474 [ 1.01858163] [ 1.03291416]\n",
      "820 0.000720247 [ 1.01736474] [ 1.03730762]\n",
      "840 0.000628997 [ 1.01622748] [ 1.04141343]\n",
      "860 0.000549309 [ 1.01516473] [ 1.0452503]\n",
      "880 0.000479716 [ 1.0141716] [ 1.04883599]\n",
      "900 0.000418938 [ 1.01324344] [ 1.05218685]\n",
      "920 0.000365864 [ 1.01237619] [ 1.05531812]\n",
      "940 0.000319511 [ 1.01156569] [ 1.05824423]\n",
      "960 0.000279033 [ 1.01080823] [ 1.06097877]\n",
      "980 0.000243683 [ 1.01010036] [ 1.06353426]\n",
      "1000 0.000212808 [ 1.00943887] [ 1.06592238]\n",
      "1020 0.000185848 [ 1.00882065] [ 1.0681541]\n",
      "1040 0.000162304 [ 1.00824308] [ 1.07023966]\n",
      "1060 0.000141743 [ 1.0077033] [ 1.07218862]\n",
      "1080 0.000123783 [ 1.00719881] [ 1.07401001]\n",
      "1100 0.000108102 [ 1.00672734] [ 1.07571208]\n",
      "1120 9.44061e-05 [ 1.00628674] [ 1.07730281]\n",
      "1140 8.24416e-05 [ 1.00587499] [ 1.07878947]\n",
      "1160 7.19958e-05 [ 1.00549018] [ 1.08017886]\n",
      "1180 6.28739e-05 [ 1.00513053] [ 1.08147693]\n",
      "1200 5.491e-05 [ 1.0047946] [ 1.08269]\n",
      "1220 4.79528e-05 [ 1.0044806] [ 1.08382356]\n",
      "1240 4.18773e-05 [ 1.00418711] [ 1.08488321]\n",
      "1260 3.65717e-05 [ 1.00391293] [ 1.08587325]\n",
      "1280 3.19372e-05 [ 1.00365663] [ 1.08679855]\n",
      "1300 2.78907e-05 [ 1.00341713] [ 1.08766305]\n",
      "1320 2.4357e-05 [ 1.00319326] [ 1.08847106]\n",
      "1340 2.12708e-05 [ 1.00298417] [ 1.08922625]\n",
      "1360 1.85766e-05 [ 1.00278878] [ 1.08993149]\n",
      "1380 1.62233e-05 [ 1.00260615] [ 1.09059107]\n",
      "1400 1.41673e-05 [ 1.00243545] [ 1.09120727]\n",
      "1420 1.23726e-05 [ 1.00227594] [ 1.09178317]\n",
      "1440 1.08047e-05 [ 1.00212681] [ 1.09232128]\n",
      "1460 9.43511e-06 [ 1.00198758] [ 1.09282422]\n",
      "1480 8.24043e-06 [ 1.0018574] [ 1.09329402]\n",
      "1500 7.19611e-06 [ 1.00173581] [ 1.09373319]\n",
      "1520 6.2855e-06 [ 1.0016222] [ 1.09414363]\n",
      "1540 5.48887e-06 [ 1.00151598] [ 1.09452701]\n",
      "1560 4.79337e-06 [ 1.00141668] [ 1.09488559]\n",
      "1580 4.18644e-06 [ 1.00132382] [ 1.09522045]\n",
      "1600 3.65557e-06 [ 1.00123715] [ 1.09553361]\n",
      "1620 3.19235e-06 [ 1.00115609] [ 1.09582615]\n",
      "1640 2.78804e-06 [ 1.00108039] [ 1.09609938]\n",
      "1660 2.43487e-06 [ 1.00100958] [ 1.09635484]\n",
      "1680 2.12627e-06 [ 1.00094354] [ 1.09659362]\n",
      "1700 1.85697e-06 [ 1.00088179] [ 1.09681666]\n",
      "1720 1.62177e-06 [ 1.00082397] [ 1.09702504]\n",
      "1740 1.41667e-06 [ 1.00077021] [ 1.09721971]\n",
      "1760 1.23708e-06 [ 1.00071967] [ 1.09740174]\n",
      "1780 1.08039e-06 [ 1.00067258] [ 1.09757185]\n",
      "1800 9.43527e-07 [ 1.00062859] [ 1.09773088]\n",
      "1820 8.23981e-07 [ 1.00058734] [ 1.09787941]\n",
      "1840 7.19655e-07 [ 1.00054884] [ 1.09801817]\n",
      "1860 6.28594e-07 [ 1.00051296] [ 1.09814787]\n",
      "1880 5.48935e-07 [ 1.00047934] [ 1.0982691]\n",
      "1900 4.79559e-07 [ 1.00044811] [ 1.09838235]\n",
      "1920 4.18798e-07 [ 1.00041878] [ 1.09848821]\n",
      "1940 3.65746e-07 [ 1.00039148] [ 1.09858716]\n",
      "1960 3.19542e-07 [ 1.00036573] [ 1.09867966]\n",
      "1980 2.78932e-07 [ 1.00034177] [ 1.09876597]\n",
      "2000 2.4365e-07 [ 1.00031948] [ 1.09884679]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train],\n",
    "                 feed_dict={X: [1, 2, 3, 4, 5],\n",
    "                            Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.10044432]\n",
      "[ 3.59964561]\n",
      "[ 2.59932613  4.5999651 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
