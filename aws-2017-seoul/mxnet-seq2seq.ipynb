{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> AWS Summit 2017 - Seoul: MXNet Seq2seq Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import mxnet as mx\n",
    "import mxnet.ndarray as nd\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)  # Config the logging\n",
    "np.random.seed(777)\n",
    "mx.random.seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1. Prepare the training set </h3>\n",
    "\n",
    "We will translate a sequence of digits \"0123456789\" to a sequence of alphabetic characters \"abcdefghij\". All sequences have length 7 and we draw a random 1000 sequences for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = \"0123456789\"\n",
    "alpha = \"abcdefghij\"\n",
    "\n",
    "char_set = list(set(digit + alpha))  # id -> char\n",
    "char_dic = {w: i for i, w in enumerate(char_set)}\n",
    "\n",
    "data_dim = len(char_set)  # one hot encoding size\n",
    "seq_length = time_steps = 7\n",
    "num_classes = len(char_set)\n",
    "batch_size = 32\n",
    "seq_num = 1000\n",
    "\n",
    "# Build training date set\n",
    "dataX = np.empty(shape=(seq_num, seq_length), dtype=np.int)\n",
    "dataY = np.empty(shape=(seq_num, seq_length), dtype=np.int)\n",
    "\n",
    "for i in range(1000):\n",
    "    rand_pick = np.random.choice(10, seq_length)\n",
    "    dataX[i, :] = [char_dic[digit[c]] for c in rand_pick]\n",
    "    dataY[i, :] = [char_dic[alpha[c]] for c in rand_pick]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2. Build the symbol </h3>\n",
    "\n",
    "Next we will build the symbol, which is used to determine the data flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')  # Shape: (N, T)\n",
    "target = mx.sym.var('target')  # Shape: (N, T)\n",
    "lstm1 = mx.rnn.FusedRNNCell(num_hidden=32, prefix=\"lstm1_\", get_next_state=True)\n",
    "lstm2 = mx.rnn.FusedRNNCell(num_hidden=32, prefix=\"lstm2_\", get_next_state=False)\n",
    "data_one_hot = mx.sym.one_hot(data, depth=data_dim)  # Shape: (N, T, C)\n",
    "data_one_hot = mx.sym.transpose(data_one_hot, axes=(1, 0, 2))  # Shape: (T, N, C)\n",
    "_, encode_state = lstm1.unroll(length=seq_length, inputs=data_one_hot, layout=\"TNC\")\n",
    "encode_state_h = encode_state[0]  # Shape: (1, N, C)\n",
    "encode_state_h = mx.sym.broadcast_to(encode_state_h, shape=(seq_length, 0, 0))  # Shape: (T, N, C)\n",
    "decode_out, _ = lstm2.unroll(length=seq_length, inputs=encode_state_h, layout=\"TNC\")\n",
    "decode_out = mx.sym.reshape(decode_out, shape=(-1, 32))\n",
    "logits = mx.sym.FullyConnected(decode_out, num_hidden=data_dim, name=\"logits\")\n",
    "logits = mx.sym.reshape(logits, shape=(seq_length, -1, data_dim))\n",
    "logits = mx.sym.transpose(logits, axes=(1, 0, 2))\n",
    "loss = mx.sym.mean(-mx.sym.pick(mx.sym.log_softmax(logits), target, axis=-1))\n",
    "loss = mx.sym.make_loss(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3. Construct the Module </h3>\n",
    "\n",
    "We will construct the Module object based on the symbol. Module will be used for training and testing. Also, the testing executor will try to reuse the allocated memory space of the training executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_desc = mx.io.DataDesc(name='data', shape=(batch_size, seq_length), layout='NT')\n",
    "label_desc = mx.io.DataDesc(name='target', shape=(batch_size, seq_length), layout='NT')\n",
    "net = mx.mod.Module(symbol=loss,\n",
    "                    data_names=['data'],\n",
    "                    label_names=['target'],\n",
    "                    context=mx.gpu())\n",
    "net.bind(data_shapes=[data_desc], label_shapes=[label_desc])\n",
    "net.init_params(initializer=mx.init.Xavier())\n",
    "net.init_optimizer(optimizer=\"adam\",\n",
    "                   optimizer_params={'learning_rate': 1E-3,\n",
    "                                     'rescale_grad': 1.0},\n",
    "                   kvstore=None)\n",
    "# We build another testing network that outputs the logits.\n",
    "test_net = mx.mod.Module(symbol=logits,\n",
    "                         data_names=[data_desc.name],\n",
    "                         label_names=None,\n",
    "                         context=mx.gpu())\n",
    "# Setting the `shared_module` to ensure that the test network shares the same parameters and\n",
    "#  allocated memory of the training network\n",
    "test_net.bind(data_shapes=[data_desc],\n",
    "              label_shapes=None,\n",
    "              for_training=False,\n",
    "              grad_req='null',\n",
    "              shared_module=net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4. Training </h3>\n",
    "\n",
    "We can fit the training set now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 cost = 1.309767440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0100 cost = 0.960539818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0150 cost = 0.708500911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0200 cost = 0.507385444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0250 cost = 0.351756732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0300 cost = 0.257590530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0350 cost = 0.183245263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.146311300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0450 cost = 0.088195475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0500 cost = 0.179716175\nLearning Finished!\nTotal Time Spent: 36.4329s\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "for epoch in range(1000):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(math.ceil(dataX.shape[0] / batch_size))\n",
    "    shuffle_ind = np.random.permutation(np.arange(dataX.shape[0]))\n",
    "    dataX = dataX[shuffle_ind, :]\n",
    "    dataY = dataY[shuffle_ind]\n",
    "    for i in range(total_batch):\n",
    "        # Slice the data batch and target batch.\n",
    "        # Note that we use np.take to ensure that the batch will be padded correctly.\n",
    "        data_npy = np.take(dataX,\n",
    "                           indices=np.arange(i * batch_size, (i+1) * batch_size),\n",
    "                           axis=0,\n",
    "                           mode=\"clip\")\n",
    "        target_npy = np.take(dataY,\n",
    "                             indices=np.arange(i * batch_size, (i + 1) * batch_size),\n",
    "                             axis=0,\n",
    "                             mode=\"clip\")\n",
    "        net.forward_backward(data_batch=mx.io.DataBatch(data=[nd.array(data_npy)],\n",
    "                                                        label=[nd.array(target_npy)]))\n",
    "        loss = net.get_outputs()[0].asscalar()\n",
    "        avg_cost += loss / total_batch\n",
    "        net.update()\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "print('Learning Finished!')\n",
    "end = time.time()\n",
    "print(\"Total Time Spent: %gs\" %(end - begin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 5. Testing </h3>\n",
    "\n",
    "Let's test the model on the random generated test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5960735  ->  fjgadfh  true:  fjgahdf\n7271477  ->  hchbhhh  true:  hchbehh\n3894109  ->  dijeajj  true:  dijebaj\n2248432  ->  cceeice  true:  cceiedc\n8108270  ->  iaaiiii  true:  ibaicha\n8119141  ->  ibbbhbg  true:  ibbjbeb\n7205813  ->  hcaffde  true:  hcafibd\n3905233  ->  djafddc  true:  djafcdd\n7089693  ->  hhijjdg  true:  haijgjd\n2956179  ->  cjgfbbb  true:  cjfgbhj\n"
     ]
    }
   ],
   "source": [
    "# Create test data set for fun\n",
    "testX = []\n",
    "testY = []\n",
    "for i in range(10):\n",
    "    rand_pick = np.random.choice(10, 7)\n",
    "    x = [char_dic[digit[c]] for c in rand_pick]\n",
    "    y = [alpha[c] for c in rand_pick]\n",
    "    testX.append(x)\n",
    "    testY.append(y)\n",
    "textX = np.array(testX, dtype=np.int)\n",
    "\n",
    "test_net.reshape(data_shapes=[mx.io.DataDesc('data', (10, seq_length))])\n",
    "predictions = test_net.predict(mx.io.NDArrayIter(textX, batch_size=10)).asnumpy()\n",
    "\n",
    "for i, prediction in enumerate(predictions):\n",
    "    x_str = [char_set[j] for j in testX[i]]\n",
    "    index = np.argmax(prediction, axis=1)\n",
    "    result = [char_set[j] for j in index]\n",
    "\n",
    "    print(''.join(x_str), ' -> ', ''.join(result),\n",
    "          \" true: \", ''.join(testY[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}